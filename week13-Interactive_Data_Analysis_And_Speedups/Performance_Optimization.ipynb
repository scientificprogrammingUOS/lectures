{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". \n",
    "# Performance Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreading & Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](multiprocessing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is a hard language to make multithreaded, mostly because of the **global interpreter lock**: Python is an interpreted language, and if the interpreter runs in only one thread, all the nice threads you're producing also run in only one thread.  \n",
    "While multi*processing* finds a way around that, even multithreading can still be of use. While multithreading can, in Python, not be **parallel**, it can still be **concurrent**. \n",
    "* *parallel* processes run truly at the same time - meaning that they must run sumultaneously on different CPU-cores\n",
    "* *concurrent* processes appear to be parallel to most of the system, even though the CPU may handle them one after another (either parallel or interlocked)\n",
    "\n",
    "While CPU-intense processes are only truly sped up when they are parallel (something where Python's multithreading doesn't help), tasks that have a bottleneck in network or disk access are helped greatly from cuncurrent execution already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To a process, there's a lot of information for the computer:\n",
    "* State of the process (ready, running, inactive)\n",
    "* Program-counter (next commans)\n",
    "* CPU registers (cashed)\n",
    "* Scheduling information (priority, position)\n",
    "* Storage information\n",
    "* I/O-Status\n",
    "* ...\n",
    "\n",
    "When switching processes, all those information needs to be saved, such that the CPU can load another process and freeze this one. This produces a lot of overhead. \n",
    "\n",
    "**Threads** are lightweight processes, using *shared resources*:\n",
    "* Shared storage space\n",
    "* Shared program code\n",
    "* Shared (virtual) files.\n",
    "\n",
    "Modern operating systems use threads to let programs switch control, without all the overhead of having to save and load all the information.   \n",
    "**Advantages**:\n",
    "* Much faster creation and task switching\n",
    "* Efficient communication between threads (unlike processes)\n",
    "* Operating system doesn't schedule them, processes can implement their own scheduling\n",
    "\n",
    "**Disadvantages**:\n",
    "* Operating system doesn't schedule them, harder to synchronize than processes\n",
    "* Processes are better isolated\n",
    "* Crashing Thread = Crashing Program  \n",
    "* Python can't use them for parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.252007194001635 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "a = np.random.rand(1000000)\n",
    "\n",
    "def sorter():\n",
    "    np.sort(a)\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "for i in range(100):\n",
    "    sorter()\n",
    "\n",
    "print(time.perf_counter() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5727858919999562 seconds\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "a = np.random.rand(1000000)\n",
    "\n",
    "def sorter():\n",
    "    np.sort(a)\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "threads = []\n",
    "for i in range(100):\n",
    "    t = threading.Thread(target=sorter)\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(time.perf_counter() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load download.py\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from urllib.request import urlopen, Request\n",
    "from time import time\n",
    "\n",
    "def get_links(client_id):\n",
    "   headers = {'Authorization': 'Client-ID {}'.format(client_id)}\n",
    "   all_ims = []\n",
    "   for page in [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]:\n",
    "       req = Request('https://api.imgur.com/3/gallery/hot/viral/month', headers=headers, method='GET')\n",
    "       with urlopen(req) as resp:\n",
    "           data = json.loads(\"\\n\".join([i.decode('utf-8') for i in resp.readlines()]))\n",
    "       all_ims = all_ims+[i['link'] for i in data['data']]\n",
    "   return all_ims\n",
    "\n",
    "\n",
    "def download_link(directory, link):\n",
    "   download_path = directory / os.path.basename(link)\n",
    "   with urlopen(link) as image, download_path.open('wb') as f:\n",
    "       for line in image.readlines():\n",
    "            f.write(line)\n",
    "\n",
    "        \n",
    "def setup_download_dir():\n",
    "   download_dir = Path('images')\n",
    "   if not download_dir.exists():\n",
    "       download_dir.mkdir()\n",
    "   return download_dir\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from urllib.request import urlopen, Request\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 39.50147891044617s\n"
     ]
    }
   ],
   "source": [
    "from download import *\n",
    "\n",
    "ts = time()\n",
    "client_id = 'f8f603617f590ed'\n",
    "download_dir = setup_download_dir()\n",
    "links = [l for l in get_links(client_id) if l.endswith('.jpg') or l.endswith('.gif') or l.endswith('.mp4')]\n",
    "for link in links:\n",
    "   download_link(download_dir, link)\n",
    "print('Took {}s'.format(time() - ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 16.887265920639038\n"
     ]
    }
   ],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "class DownloadWorker(Thread):\n",
    "   def __init__(self, queue):\n",
    "       Thread.__init__(self)\n",
    "       self.queue = queue\n",
    "\n",
    "   def run(self):\n",
    "       while True:\n",
    "           # Get the work from the queue and expand the tuple\n",
    "           directory, link = self.queue.get()\n",
    "           download_link(directory, link)\n",
    "           self.queue.task_done()\n",
    "\n",
    "ts = time()\n",
    "client_id = 'f8f603617f590ed'\n",
    "download_dir = setup_download_dir()\n",
    "links = [l for l in get_links(client_id) if l.endswith('.jpg') or l.endswith('.gif') or l.endswith('.mp4')]\n",
    "# Create a queue to communicate with the worker threads\n",
    "queue = Queue()\n",
    "# Create 8 worker threads\n",
    "for x in range(8):\n",
    "   worker = DownloadWorker(queue)\n",
    "   # Setting daemon to True will let the main thread exit even though the workers are blocking\n",
    "   worker.daemon = True\n",
    "   worker.start()\n",
    "# Put the tasks into the queue as a tuple\n",
    "for link in links:\n",
    "   queue.put((download_dir, link))\n",
    "# Causes the main thread to wait for the queue to finish processing all the tasks\n",
    "queue.join()\n",
    "print('Took {}'.format(time() - ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, there is a class ``DownloadWorker``, which *is* a Python Thread. On every iteration of it's run, it calls ``self.queue.get()``, which fetches a URL from a thread-safe queue. Once the worker recieves such an item, it calls the ``download_link`` method that we used before. Then the worker must signal the queue that the task is done -- if not, ``queue.join()`` would block the main thread forever.  \n",
    "\n",
    "Note that while this method is concurrent, it is **not parallel** due to Python's GIL! - it is faster because the IO is the bottleneck in this task! The processor is mostly waiting, and can pick up working on a thread as soon as the network is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing \n",
    "If code is performing a CPU-heavy task, the execution time will probably be **slower**!  \n",
    "For such tasks, we need the ``multiprocessing`` module!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use multiple processing, what we generally do is to create a multiprocessing ``Pool``, which provides a method ``map``. This method is passed a list of URLs to the pool, which spawns individual processes - processes that can execute our download of the images *truly parallel*.  \n",
    "As mentioned above, the disadvantage of this method is that the entire memory of the script must be copied to every created subprocess, including all its overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 22.002023458480835s\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from multiprocessing.pool import Pool\n",
    "\n",
    "ts = time()\n",
    "client_id = 'f8f603617f590ed'\n",
    "download_dir = setup_download_dir()\n",
    "links = [l for l in get_links(client_id) if l.endswith('.jpg') or l.endswith('.gif') or l.endswith('.mp4')]\n",
    "download = partial(download_link, download_dir)\n",
    "with Pool(8) as p:\n",
    "   p.map(download, links)\n",
    "print('Took {}s'.format(time() - ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.python.org/2/library/multiprocessing.html#using-a-pool-of-workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Async/Await\n",
    "\n",
    "Next to multiprocessing and multithreading for parallel processing, Python also provides the possibility for **asynchronous programming**, a different paradigm for parallel programming, mostly known from Javascript: [https://www.youtube.com/watch?v=3CmKIUmLmJo](https://www.youtube.com/watch?v=3CmKIUmLmJo)  \n",
    "\n",
    "For an example of that, it is referred to the full version of the source of this code and explanations at [https://www.toptal.com/python/beginners-guide-to-concurrency-and-parallelism-in-python](https://www.toptal.com/python/beginners-guide-to-concurrency-and-parallelism-in-python)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='slope', max=2.0, min=-2.0), FloatSlider(value=0.0, dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interactive\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def f(slope, intercept):\n",
    "    fig, ax = plt.subplots()\n",
    "    x = np.linspace(-10, 10, num=1000)\n",
    "    ax.plot(x, slope * x + intercept)\n",
    "    ax.set_ylim(-5, 5)\n",
    "    plt.show()\n",
    "\n",
    "interactive_plot = interactive(f, slope=(-2.0, 2.0), intercept=(-3, 3, 0.5))\n",
    "output = interactive_plot.children[-1]\n",
    "output.layout.height = '350px'\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(10_000).reshape(100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "go_slow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "go_fast(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cython\n",
    "\n",
    "* one way to make your program run faster: compile to a faster language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Computing\n",
    "\n",
    "* second way to make it faster: make a computation graph & distribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask\n",
    "https://dask.org/\n",
    "\n",
    "tbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
